import os
import json
import time
import logging
from wsgiref import headers
import httpx
from httpx_sse import connect_sse
from kafka import KafkaProducer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

# --- 1. ì„¤ì •ê°’ ë¶ˆëŸ¬ì˜¤ê¸° (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©) ---
KAFKA_BROKER = os.getenv("KAFKA_BROKER", "localhost:9092")
KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "wikimedia.recentchange")
WIKIMEDIA_URL = "https://stream.wikimedia.org/v2/stream/recentchange"


def create_kafka_producer():
    """
    Kafka Producer ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.
    ì—°ê²°ì— ì‹¤íŒ¨í•˜ë©´ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    """
    while True:
        try:
            producer = KafkaProducer(
                bootstrap_servers=KAFKA_BROKER.split(","),
                value_serializer=lambda v: json.dumps(v).encode("utf-8"),
                retries=5,
                request_timeout_ms=30000,
            )
            logging.info("âœ… Kafka Producerì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return producer
        except Exception as e:
            logging.error(f"âŒ Kafka Producer ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            logging.info("5ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(5)


def run_wiki_stream():
    """
    ë©”ì¸ í•¨ìˆ˜: SSE ìŠ¤íŠ¸ë¦¼ì— ì—°ê²°í•˜ê³  ë©”ì‹œì§€ë¥¼ Kafkaë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    producer = create_kafka_producer()

    while True:  # ì™¸ë¶€ ë£¨í”„: ì—°ê²° ëŠê¹€ ì‹œ ì¬ì‹œë„ë¥¼ ìœ„í•´ ì¶”ê°€
        try:
            logging.info(f"Wikimedia SSE ìŠ¤íŠ¸ë¦¼ì— ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤: {WIKIMEDIA_URL}")
            # httpx í´ë¼ì´ì–¸íŠ¸ ìƒì„±: ìŠ¤íŠ¸ë¦¬ë°ì´ë¯€ë¡œ timeoutì„ Noneìœ¼ë¡œ ì„¤ì •
            headers = {"User-Agent": "wikiStreams-project/0.1 (puding2564@gmail.com)"}
            with httpx.Client(timeout=None, headers=headers) as client:
                # SSE ì—°ê²°
                with connect_sse(client, "GET", WIKIMEDIA_URL) as event_source:
                    logging.info("âœ… Wikimedia SSE ìŠ¤íŠ¸ë¦¼ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    for sse in event_source.iter_sse():
                        # ë°ì´í„°ê°€ ì—†ëŠ” ì´ë²¤íŠ¸(keep-alive ë“±)ëŠ” ê±´ë„ˆëœ€
                        if not sse.data:
                            continue

                        try:
                            # JSON ë°ì´í„° íŒŒì‹±
                            data = json.loads(sse.data)

                            # --- Kafkaë¡œ ë°ì´í„°ë¥¼ ì˜ëŠ” ì§€ì  ---
                            producer.send(KAFKA_TOPIC, value=data)

                            # í˜„ì¬ ì–´ë–¤ ë°ì´í„°ê°€ ì „ì†¡ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ë¡œê·¸ (ì„ íƒ ì‚¬í•­)
                            if "title" in data:
                                logging.info(
                                    f"ğŸ“¨ ë©”ì‹œì§€ ì „ì†¡ë¨: {data.get('meta', {}).get('domain', '')} - {data.get('title', '')}"
                                )

                        except json.JSONDecodeError:
                            logging.warning(
                                f"âš ï¸ ì˜ëª»ëœ JSON ë°ì´í„°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {sse.data}"
                            )
                        except Exception as e:
                            logging.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        except httpx.HTTPError as e:
            # httpx ê´€ë ¨ ë„¤íŠ¸ì›Œí¬/HTTP ì˜¤ë¥˜ ì²˜ë¦¬
            logging.error(f"âŒ HTTPX ì˜¤ë¥˜ ë°œìƒ: {e}")
            logging.info("10ì´ˆ í›„ ì¬ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(10)
        except Exception as e:
            # ê·¸ ì™¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì²˜ë¦¬
            logging.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            logging.info("10ì´ˆ í›„ ì¬ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(10)


if __name__ == "__main__":
    run_wiki_stream()
